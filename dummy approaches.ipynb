{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import *\n",
    "from abstract_classifier import AbstractClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DataReader(tokenize_with_nlkt)\n",
    "train_1 = dr.read_data('data/train_text_1.txt')\n",
    "tags_train_1 = dr.read_tags('data/train_tags_1.txt')\n",
    "train_2 = dr.read_data('data/train_text_2.txt')\n",
    "tags_train_2 = dr.read_tags('data/train_tags_2.txt')\n",
    "\n",
    "test_1 = dr.read_data('data/test_text_1.txt')\n",
    "tags_test_1 = dr.read_tags('data/test_tags_1.txt')\n",
    "test_2 = dr.read_data('data/test_text_2.txt')\n",
    "tags_test_2 = dr.read_tags('data/test_tags_2.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounter:\n",
    "    \n",
    "    def __init__(self, data, classes, no_classes = 2):\n",
    "    \n",
    "        counter = defaultdict(int)\n",
    "        class_counter = []\n",
    "        for i in range(no_classes):\n",
    "            class_counter.append(defaultdict(int))\n",
    "        \n",
    "        wordset = []\n",
    "    \n",
    "        for tweet, tweet_class in tqdm(zip(data, classes)):\n",
    "            for word in tweet:\n",
    "                counter[word] += 1\n",
    "                class_counter[tweet_class][word] += 1\n",
    "                wordset.append(word)\n",
    "        \n",
    "        self.wordset = list(set(wordset))\n",
    "        \n",
    "        self.no_classes = no_classes\n",
    "        self.counter = counter\n",
    "        self.class_counter = class_counter\n",
    "        \n",
    "        self.save_most_dominant()\n",
    "        \n",
    "    def ask(self, word):\n",
    "        \n",
    "        total = self.counter[word]\n",
    "        classes = [self.class_counter[i][word] for i in range(self.no_classes)]\n",
    "        return (total, np.array(classes))\n",
    "    \n",
    "    def ask_distribution(self, word):\n",
    "        \n",
    "        total, over_classes = self.ask(word)\n",
    "        scaled_over_classes = np.array(over_classes, dtype = float)\n",
    "        scaled_over_classes /= float(total)\n",
    "        \n",
    "        return scaled_over_classes\n",
    "\n",
    "    def save_most_dominant(self, K = 25):\n",
    "        \n",
    "        most_dominant = []\n",
    "        for i in range(self.no_classes):\n",
    "            most_dominant.append([])\n",
    "        \n",
    "        for word in self.wordset:\n",
    "            \n",
    "            scaled_over_classes = self.ask_distribution(word)\n",
    "            \n",
    "            for i in range(self.no_classes):\n",
    "                if scaled_over_classes[i] < 0.99 and scaled_over_classes[i] > (1 / self.no_classes):\n",
    "                    most_dominant[i].append((scaled_over_classes[i], word))\n",
    "        \n",
    "        self.keywords = []\n",
    "        \n",
    "        for i in range(self.no_classes):\n",
    "            most_dominant[i] = sorted(most_dominant[i], reverse = True)\n",
    "            if len(most_dominant[i]) > K:\n",
    "                most_dominant[i] = most_dominant[i][:K]\n",
    "            print(most_dominant[i])\n",
    "            \n",
    "            self.keywords.append([])\n",
    "            for frac, word in most_dominant[i]:\n",
    "                self.keywords[i].append(word)\n",
    "            \n",
    "            print(self.keywords[i])\n",
    "    \n",
    "    def tweet_class_distribution(self, tweet):\n",
    "        \n",
    "        \n",
    "        res = np.ones(self.no_classes)\n",
    "        res[0] = 1.01\n",
    "        \n",
    "        my_keywords = []\n",
    "        for i in range(1, self.no_classes):\n",
    "            my_keywords += self.keywords[i]\n",
    "        \n",
    "        my_keywords = list(set(my_keywords))\n",
    "        \n",
    "        \n",
    "        for word in tweet:\n",
    "            #print(word)\n",
    "            if word in my_keywords:\n",
    "                \n",
    "                weights = 1 + self.ask_distribution(word)\n",
    "                res *= weights\n",
    "        \n",
    "        return res\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc1 = WordCounter(train_1, tags_train_1, no_classes = 2)\n",
    "wc2 = WordCounter(train_2, tags_train_2, no_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_classifier_1 = AbstractClassifier(wc1)\n",
    "wc_classifier_2 = AbstractClassifier(wc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_classifier_1.run_and_save(test_1, 'data/answers1wc.txt')\n",
    "wc_classifier_2.run_and_save(test_2, 'data/answers2wc.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ee766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self, word_counter):\n",
    "\n",
    "        \n",
    "        self.no_classes = word_counter.no_classes\n",
    "        self.wordset = word_counter.wordset\n",
    "        \n",
    "        counts = []\n",
    "        \n",
    "        for word in word_counter.wordset:\n",
    "            counts.append(word_counter.ask(word)[1])\n",
    "        \n",
    "        counts = np.array(counts)\n",
    "        \n",
    "        self.df = pd.DataFrame(index = word_counter.wordset,\n",
    "                          columns = np.arange(word_counter.no_classes), data = counts)\n",
    "        \n",
    "        self.df /= self.df.sum(0)\n",
    "        \n",
    "        self.log_df = np.log(1e-100 + self.df)\n",
    "    \n",
    "    def tweet_class_distribution(self, tweet):\n",
    "        \n",
    "        log_probs = np.zeros(self.no_classes)\n",
    "    \n",
    "        apriori_prob = -np.log(self.no_classes)\n",
    "        prob_d = 0\n",
    "\n",
    "        for cur_class in range(self.no_classes):\n",
    "            cur_prob = apriori_prob\n",
    "            for word in tweet:\n",
    "                if word not in self.wordset:\n",
    "                    continue\n",
    "                cur_prob += (self.log_df.loc[word, cur_class])\n",
    "            log_probs[cur_class] = cur_prob\n",
    "            prob_d += np.exp(cur_prob)\n",
    "    \n",
    "        prob_d = np.log(prob_d)\n",
    "    \n",
    "        probs = np.zeros(self.no_classes)\n",
    "        \n",
    "        for cur_class in range(self.no_classes):\n",
    "            p = log_probs[cur_class] - prob_d\n",
    "            probs[cur_class] = np.exp(p)\n",
    "        \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb1 = NaiveBayes(wc1)\n",
    "nb2 = NaiveBayes(wc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1775e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_1 = AbstractClassifier(nb1)\n",
    "nb_classifier_2 = AbstractClassifier(nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_1.run_and_save(test_1, 'data/answers1nb.txt')\n",
    "nb_classifier_2.run_and_save(test_2, 'data/answers2nb.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb669ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61dd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
